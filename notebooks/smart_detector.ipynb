{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d83d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu118\n",
      "0.18.1+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)         # 2.3.1+cu118\n",
    "print(torchvision.__version__)   # 0.18.1+cu118\n",
    "print(torch.cuda.is_available()) # True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eaa6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import base64\n",
    "import torch\n",
    "import threading\n",
    "import numpy as np\n",
    "import cvzone\n",
    "import logging\n",
    "from ultralytics import YOLO\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === Configuration ===\n",
    "VIDEO_PATH = \"circulation.mp4\"\n",
    "YOLO_MODEL_PATH = \"yolo12m.pt\"\n",
    "OUTPUT_FOLDER = \"cropped_vehicles\"\n",
    "ALLOWED_CLASSES = {\"car\", \"truck\", \"bus\", \"motorcycle\", \"bicycle\"}\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key_env = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Initialize OpenAI-compatible client (e.g., OpenRouter)\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key_env,\n",
    ")\n",
    "\n",
    "# Logger setup\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "class SmartVehicleDetector:\n",
    "    def __init__(self, video_file: str, yolo_model_path: str = YOLO_MODEL_PATH):\n",
    "        self._load_yolo_model(yolo_model_path)\n",
    "        self.cap = self._open_video_file(video_file)\n",
    "        self.area = np.array([(420, 407), (382, 448), (940, 456), (930, 419)], np.int32)\n",
    "        self.processed_track_ids = set()\n",
    "        self.detected_country = \"Unknown\"\n",
    "        self.current_date = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        self.vehicle_data_list = []\n",
    "        self.output_json_path = f\"vehicle_data_{self.current_date}.json\"\n",
    "        if not os.path.exists(self.output_json_path):\n",
    "            with open(self.output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([], f, indent=4)\n",
    "            logging.info(f\"üìù JSON output initialized: {self.output_json_path}\")\n",
    "\n",
    "        self.cropped_images_folder = OUTPUT_FOLDER\n",
    "        os.makedirs(self.cropped_images_folder, exist_ok=True)\n",
    "\n",
    "    def _load_yolo_model(self, path: str):\n",
    "        try:\n",
    "            self.yolo_model = YOLO(path)\n",
    "            self.names = self.yolo_model.names\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.yolo_model.to(self.device)\n",
    "            logging.info(f\"‚úÖ YOLO model loaded on {self.device.upper()}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"‚ùå Failed to load YOLO model: {e}\")\n",
    "\n",
    "    def _open_video_file(self, path: str):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        if not cap.isOpened():\n",
    "            raise FileNotFoundError(f\"‚ùå Could not open video file: {path}\")\n",
    "        return cap\n",
    "\n",
    "    def encode_image_to_base64(self, image):\n",
    "        _, buffer = cv2.imencode(\".jpg\", image)\n",
    "        return base64.b64encode(buffer).decode(\"utf-8\")\n",
    "\n",
    "    def detect_country_from_scene(self, frame):\n",
    "        \"\"\"Send the first clean frame to the LLM to estimate the country.\"\"\"\n",
    "        try:\n",
    "            base64_img = self.encode_image_to_base64(frame)\n",
    "\n",
    "            prompt = (\n",
    "                \"You are an expert in geolocation and vehicle classification. \"\n",
    "                \"From the image provided, analyze the visual scene (vehicles, road signs, license plates, environment) \"\n",
    "                \"and deduce the most likely country. Only return the name of the country.\"\n",
    "            )\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"google/gemini-2.5-flash-lite\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img}\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            country_name = completion.choices[0].message.content.strip()\n",
    "            logging.info(f\"üåç Country detected from scene: {country_name}\")\n",
    "            return country_name\n",
    "        except Exception as e:\n",
    "            logging.error(f\"‚ùå Failed to detect country: {e}\")\n",
    "            return \"Unknown\"\n",
    "\n",
    "    def analyze_image_with_openai(self, image_path):\n",
    "        \"\"\"Send a cropped vehicle image to the LLM for recognition based on the detected country.\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as img_file:\n",
    "                base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "            prompt = (\n",
    "                f\"You are an expert in vehicle recognition. The vehicle is from {self.detected_country}. \"\n",
    "                \"Analyze the image and extract:\\n\"\n",
    "                \"1. Vehicle Type (e.g. car, truck, bus, motorcycle, bicycle)\\n\"\n",
    "                \"2. Vehicle Color (e.g. red, black, white)\\n\"\n",
    "                \"3. Vehicle Brand (e.g. Toyota, Ford)\\n\\n\"\n",
    "                \"Return only this table:\\n\"\n",
    "                \"| Vehicle Type | Vehicle Color | Vehicle Company |\\n\"\n",
    "                \"|--------------|---------------|-----------------|\\n\"\n",
    "            )\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"google/gemini-2.5-flash-lite\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            return completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"‚ùå OpenAI vehicle analysis failed: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def process_crop_image(self, image, track_id):\n",
    "        \"\"\"Crop vehicle image, send to LLM, and save structured JSON data.\"\"\"\n",
    "        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        image_filename = os.path.join(self.cropped_images_folder, f\"vehicle_{track_id}_{timestamp}.jpg\")\n",
    "        cv2.imwrite(image_filename, image)\n",
    "\n",
    "        response = self.analyze_image_with_openai(image_filename)\n",
    "        lines = response.split(\"\\n\")[2:]\n",
    "\n",
    "        for line in lines:\n",
    "            if \"--------------\" in line or not line.strip():\n",
    "                continue\n",
    "            values = [col.strip() for col in line.split(\"|\")[1:-1]]\n",
    "            if len(values) == 3:\n",
    "                v_type, v_color, v_brand = values\n",
    "                entry = {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"track_id\": track_id,\n",
    "                    \"vehicle_type\": v_type,\n",
    "                    \"vehicle_color\": v_color,\n",
    "                    \"vehicle_company\": v_brand\n",
    "                }\n",
    "                self.vehicle_data_list.append(entry)\n",
    "                logging.info(f\"üöó JSON entry added for track ID {track_id}\")\n",
    "                self._save_json_data()\n",
    "\n",
    "    def crop_and_process(self, clean_frame, box, track_id):\n",
    "        \"\"\"Crop vehicle from the clean frame and send for analysis.\"\"\"\n",
    "        if track_id in self.processed_track_ids:\n",
    "            return\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cropped_image = clean_frame[y1:y2, x1:x2]\n",
    "        self.processed_track_ids.add(track_id)\n",
    "        threading.Thread(target=self.process_crop_image, args=(cropped_image, track_id), daemon=True).start()\n",
    "\n",
    "    def process_video_frame(self, clean_frame):\n",
    "        \"\"\"Detect and track vehicles in a single frame.\"\"\"\n",
    "        frame = clean_frame.copy()\n",
    "        frame = cv2.resize(frame, (1020, 600))\n",
    "        clean_frame_resized = frame.copy()\n",
    "\n",
    "        results = self.yolo_model.track(frame, persist=True, device=self.device)\n",
    "\n",
    "        if results and results[0].boxes is not None:\n",
    "            boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
    "            class_ids = results[0].boxes.cls.int().cpu().tolist()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist() if results[0].boxes.id is not None else [-1] * len(boxes)\n",
    "\n",
    "            for box, track_id, class_id in zip(boxes, track_ids, class_ids):\n",
    "                class_name = self.names[class_id]\n",
    "                if class_name not in ALLOWED_CLASSES:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                if cv2.pointPolygonTest(self.area, (x2, y2), False) >= 0:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "                    cvzone.putTextRect(frame, f\"ID: {track_id}\", (x2, y2), 1, 1)\n",
    "                    cvzone.putTextRect(frame, class_name, (x1, y1), 1, 1)\n",
    "                    self.crop_and_process(clean_frame_resized, box, track_id)\n",
    "\n",
    "        cvzone.putTextRect(frame, f\"Country: {self.detected_country}\", (10, 30), 1, 2)\n",
    "        return frame\n",
    "\n",
    "    def _save_json_data(self):\n",
    "        \"\"\"Save vehicle data list to JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(self.output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(self.vehicle_data_list, f, indent=4)\n",
    "            logging.debug(\"‚úÖ JSON file updated.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"‚ùå Error saving JSON file: {e}\")\n",
    "\n",
    "    def start_processing(self):\n",
    "        logging.info(\"üé¨ Starting video processing...\")\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            self.detected_country = self.detect_country_from_scene(frame)\n",
    "\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            annotated_frame = self.process_video_frame(frame)\n",
    "            cv2.polylines(annotated_frame, [self.area], True, (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Smart Vehicle Detector\", annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        logging.info(f\"‚úÖ Data saved to {self.output_json_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = SmartVehicleDetector(VIDEO_PATH)\n",
    "    processor.start_processing()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_vehicle_env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
